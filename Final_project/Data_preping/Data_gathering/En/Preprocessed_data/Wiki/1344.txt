central processing unit cpu also called central processor main processor processor electronic circuitry executes instruction comprising computer program
cpu performs basic arithmetic logic controlling inputoutput io operation specified instruction program
contrast external component main memory io circuitry specialized processor graphic processing unit gpus
form design implementation cpu changed time fundamental operation remains almost unchanged
principal component cpu include arithmetic-logic unit alu performs arithmetic logic operation processor register supply operand alu store result alu operation control unit orchestrates fetching memory decoding execution instruction directing coordinated operation alu register components
modern cpu implemented integrated circuit ic microprocessor one cpu single ic chip
individual physical cpu processor core also multithreaded create additional virtual logical cpus
ic contains cpu may also contain memory peripheral interface component computer integrated device variously called microcontrollers system chip soc
array processor vector processor multiple processor operate parallel unit considered central
early computer eniac physically rewired perform different task caused machine called fixed-program computers
central processing unit term ha use since early as
since term cpu generally defined device software computer program execution earliest device could rightly called cpu came advent stored-program computer
presper eckert john william mauchly's eniac wa initially omitted could finished sooner
june eniac wa made mathematician john von neumann distributed paper entitled first draft report edvac
wa outline stored-program computer would eventually completed august
edvac wa designed perform certain number instruction operation various types
significantly program written edvac stored high-speed computer memory rather specified physical wiring computer
overcame severe limitation eniac wa considerable time effort required reconfigure computer perform new task
von neumann's design program edvac ran could changed simply changing content memory
edvac however wa first stored-program computer manchester baby small-scale experimental stored-program computer ran first program june manchester mark ran first program night june
early cpu custom design used part larger sometimes distinctive computer
however method designing custom cpu particular application ha largely given way development multi-purpose processor produced large quantities
standardization began era discrete transistor mainframe minicomputer ha rapidly accelerated popularization integrated circuit ic
ic ha allowed increasingly complex cpu designed manufactured tolerance order nanometers
miniaturization standardization cpu increased presence digital device modern life far beyond limited application dedicated computing machines
modern microprocessor appear electronic device ranging automobile cellphone sometimes even toys
von neumann often credited design stored-program computer design edvac design became known von neumann architecture others konrad zuse suggested implemented similar ideas
so-called harvard architecture harvard mark wa completed edvac also used stored-program design using punched paper tape rather electronic memory
key difference von neumann harvard architecture latter separate storage treatment cpu instruction data former us memory space both
modern cpu primarily von neumann design cpu harvard architecture seen well especially embedded application instance atmel avr microcontrollers harvard architecture processors
relay vacuum tube thermionic tube commonly used switching element useful computer requires thousand ten thousand switching devices
vacuum-tube computer edvac tended average eight hour failure whereas relay computer like slower earlier harvard mark failed rarely
end tube-based cpu became dominant significant speed advantage afforded generally outweighed reliability problems
early synchronous cpu ran low clock rate compared modern microelectronic designs
clock signal frequency ranging khz mhz common time limited largely speed switching device built with
design complexity cpu increased various technology facilitated building smaller reliable electronic devices
transistorized cpu longer built bulky unreliable fragile switching element like vacuum tube relays
improvement complex reliable cpu built onto one several printed circuit board containing discrete individual components
ibm introduced ibm system computer architecture wa used series computer capable running program different speed performance
wa significant time electronic computer incompatible one another even made manufacturer
facilitate improvement ibm used concept microprogram often called microcode still see widespread usage modern cpus
system architecture wa popular dominated mainframe computer market decade left legacy still continued similar modern computer like ibm zseries
digital equipment corporation dec introduced another influential computer aimed scientific research market pdp-
aside facilitating increased reliability lower power consumption transistor also allowed cpu operate much higher speed short switching time transistor comparison tube relay
increased reliability dramatically increased speed switching element almost exclusively transistor time cpu clock rate ten megahertz easily obtained period
additionally discrete transistor ic cpu heavy usage new high-performance design like single instruction multiple data simd vector processor began appear
early experimental design later gave rise era specialized supercomputer like made cray inc fujitsu ltd
period method manufacturing many interconnected transistor compact space wa developed
integrated circuit ic allowed large number transistor manufactured single semiconductor-based die chip
first basic non-specialized digital circuit gate miniaturized ics
cpu based building block ic generally referred small-scale integration ssi devices
ssi ic one used apollo guidance computer usually contained dozen transistors
build entire cpu ssi ic required thousand individual chip still consumed much le space power earlier discrete transistor designs
ibm's system follow-on system used ssi ic rather solid logic technology discrete-transistor modules
dec's pdp-i ki pdp- also switched individual transistor used pdp- pdp- ssi ic extremely popular pdp- line wa originally built ssi ic wa eventually implemented lsi component became practical
lee boysel published influential article including manifesto described build equivalent bit mainframe computer relatively small number large-scale integration circuit lsi
way build lsi chip chip hundred gate wa build using metal-oxide-semiconductor mo semiconductor manufacturing process either pmos logic nmos logic cmos logic
however company continued build processor bipolar transistor-transistor logic ttl chip bipolar junction transistor faster mo chip company datapoint continued build processor ttl chip early s
mo ic slower initially considered useful application required low power
following development silicon-gate mo technology federico faggin fairchild semiconductor mo ic largely replaced bipolar ttl standard chip technology early s
microelectronic technology advanced increasing number transistor placed ic decreasing number individual ic needed complete cpu
msi lsi ic increased transistor count hundred thousands
number ic required build complete cpu reduced ic eight different type ic containing roughly mosfets
stark contrast ssi msi predecessor first lsi implementation pdp- contained cpu composed four lsi integrated circuits
since introduction first commercially available microprocessor intel first widely used microprocessor intel class cpu ha almost completely overtaken central processing unit implementation methods
mainframe minicomputer manufacturer time launched proprietary ic development program upgrade older computer architecture eventually produced instruction set compatible microprocessor backward-compatible older hardware software
combined advent eventual success ubiquitous personal computer term cpu applied almost exclusively microprocessors
several cpu denoted core combined single processing chip
previous generation cpu implemented discrete component numerous small integrated circuit ic one circuit boards
microprocessor hand cpu manufactured small number ic usually one
overall smaller cpu size result implemented single die mean faster switching time physical factor like decreased gate parasitic capacitance
ha allowed synchronous microprocessor clock rate ranging ten megahertz several gigahertz
additionally ability construct exceedingly small transistor ic ha increased complexity number transistor single cpu many fold
widely observed trend described moore's law proven fairly accurate predictor growth cpu ic complexity until
complexity size construction general form cpu changed enormously since basic design function ha changed much all
almost common cpu today accurately described von neumann stored-program machines
moore's law longer hold concern arisen limit integrated circuit transistor technology
extreme miniaturization electronic gate causing effect phenomenon like electromigration subthreshold leakage become much significant
newer concern among many factor causing researcher investigate new method computing quantum computer well expand usage parallelism method extend usefulness classical von neumann model
fundamental operation cpu regardless physical form take execute sequence stored instruction called program
nearly cpu follow fetch decode execute step operation collectively known instruction cycle
execution instruction entire process repeat next instruction cycle normally fetching next-in-sequence instruction incremented value program counter
jump instruction wa executed program counter modified contain address instruction wa jumped program execution continues normally
complex cpu multiple instruction fetched decoded executed simultaneously
section describes generally referred classic risc pipeline quite common among simple cpu used many electronic device often called microcontrollers
largely ignores important role cpu cache therefore access stage pipeline
instruction manipulate program counter rather producing result data directly instruction generally called jump facilitate program behavior like loop conditional program execution use conditional jump existence functions
flag used influence program behaves since often indicate outcome various operations
example processor compare instruction evaluates two value set clear bit flag register indicate one greater whether equal one flag could used later jump instruction determine program flow
first step fetch involves retrieving instruction represented number sequence number program memory
instruction's location address program memory determined program counter pc called instruction pointer intel x microprocessor store number identifies address next instruction fetched
instruction fetched pc incremented length instruction contain address next instruction sequence
often instruction fetched must retrieved relatively slow memory causing cpu stall waiting instruction returned
issue largely addressed modern processor cache pipeline architecture see below
decode step performed binary decoder circuitry known instruction decoder instruction converted signal control part cpu
way instruction interpreted defined cpu's instruction set architecture isa
often one group bit field within instruction called opcode indicates operation performed remaining field usually provide supplemental information required operation operands
operand may specified constant value called immediate value location value may processor register memory address determined addressing mode
cpu design instruction decoder implemented hardwired unchangeable binary decoder circuit
others microprogram used translate instruction set cpu configuration signal applied sequentially multiple clock pulses
case memory store microprogram rewritable making possible change way cpu decodes instructions
depending cpu architecture may consist single action sequence actions
action control signal electrically enable disable various part cpu perform part desired operation
often result written internal cpu register quick access subsequent instructions
case result may written slower le expensive higher capacity main memory
example addition instruction executed register containing operand number summed activated part arithmetic logic unit alu perform addition
clock pulse occurs operand flow source register alu sum appears output
subsequent clock pulse component enabled disabled move output sum operation storage eg register memory
resulting sum large ie larger alu's output word size arithmetic overflow flag set influencing next operation
hardwired cpu's circuitry set basic operation perform called instruction set
operation may involve example adding subtracting two number comparing two number jumping different part program
instruction represented unique combination bit known machine language opcode
processing instruction cpu decodes opcode via binary decoder control signal orchestrate behavior cpu
complete machine language instruction consists opcode many case additional bit specify argument operation example number summed case addition operation
going complexity scale machine language program collection machine language instruction cpu executes
actual mathematical operation instruction performed combinational logic circuit within cpu's processor known arithmetic-logic unit alu
general cpu executes instruction fetching memory using alu perform operation storing result memory
beside instruction integer mathematics logic operation various machine instruction exist loading data memory storing back branching operation mathematical operation floating-point number performed cpu's floating-point unit fpu
control unit cu component cpu directs operation processor
tell computer's memory arithmetic logic unit input output device respond instruction sent processor
john von neumann included control unit part von neumann architecture
modern computer design control unit typically internal part cpu overall role operation unchanged since introduction
arithmetic logic unit alu digital circuit within processor performs integer arithmetic bitwise logic operations
input alu data word operated called operand status information previous operation code control unit indicating operation perform
depending instruction executed operand may come internal cpu register external memory may constant generated alu itself
input signal settled propagated alu circuitry result performed operation appears alu's outputs
result consists data word may stored register memory status information typically stored special internal cpu register reserved purpose
address generation unit agu sometimes also called address computation unit acu execution unit inside cpu calculates address used cpu access main memory
address calculation handled separate circuitry operates parallel rest cpu number cpu cycle required executing various machine instruction reduced bringing performance improvements
performing various operation cpu need calculate memory address required fetching data memory example in-memory position array element must calculated cpu fetch data actual memory locations
address-generation calculation involve different integer arithmetic operation addition subtraction modulo operation bit shifts
often calculating memory address involves one general-purpose machine instruction necessarily decode execute quickly
incorporating agu cpu design together introducing specialized instruction use agu various address-generation calculation offloaded rest cpu often executed quickly single cpu cycle
thus agus implement expose address-calculation operation also include advanced specialized instruction operate multiple operand time
furthermore cpu architecture include multiple agus one address-calculation operation executed simultaneously bringing performance improvement capitalizing superscalar nature advanced cpu designs
example intel incorporates multiple agus sandy bridge haswell microarchitectures increase bandwidth cpu memory subsystem allowing multiple memory-access instruction executed parallel
many microprocessor smartphones desktop laptop server computer memory management unit translating logical address physical ram address providing memory protection paging ability useful virtual memory
cpu cache hardware cache used central processing unit cpu computer reduce average cost time energy access data main memory
cache smaller faster memory closer processor core store copy data frequently used main memory locations
cpu different independent cache including instruction data cache data cache usually organized hierarchy cache level l l l l etc
modern fast cpu specialized exception multiple level cpu caches
first cpu used cache one level cache unlike later level cache wa split ld data li instructions
also l cache larger processor l cache well
l cache usually split act common repository already split l cache
every core multi-core processor ha dedicated l cache usually shared cores
l cache currently uncommon generally dynamic random-access memory dram rather static random-access memory sram separate die chip
wa also case historically l bigger chip allowed integration generally cache level possible exception last level
type cache exist counted towards cache size important cache mentioned translation lookaside buffer tlb part memory management unit mmu cpu have
kib mib larger non-l size although ibm z ha kib l instruction cache
cpu synchronous circuit mean employ clock signal pace sequential operations
clock signal produced external oscillator circuit generates consistent number pulse second form periodic square wave
frequency clock pulse determines rate cpu executes instruction consequently faster clock instruction cpu execute second
ensure proper operation cpu clock period longer maximum time needed signal propagate move cpu
setting clock period value well worst-case propagation delay possible design entire cpu way move data around edge rising falling clock signal
ha advantage simplifying cpu significantly design perspective component-count perspective
however also carry disadvantage entire cpu must wait slowest element even though portion much faster
limitation ha largely compensated various method increasing cpu parallelism see below
however architectural improvement alone solve drawback globally synchronous cpus
higher clock rate increasingly complex cpu make difficult keep clock signal phase synchronized throughout entire unit
ha led many modern cpu require multiple identical clock signal provided avoid delaying single signal significantly enough cause cpu malfunction
another major issue clock rate increase dramatically amount heat dissipated cpu
constantly changing clock cause many component switch regardless whether used time
general component switching us energy element static state
therefore clock rate increase doe energy consumption causing cpu require heat dissipation form cpu cooling solutions
one method dealing switching unneeded component called clock gating involves turning clock signal unneeded component effectively disabling them
however often regarded difficult implement therefore doe see common usage outside low-power designs
one notable recent cpu design us extensive clock gating ibm powerpc-based xenon used xbox way power requirement xbox greatly reduced
another method addressing problem global clock signal removal clock signal altogether
removing global clock signal make design process considerably complex many way asynchronous clockless design carry marked advantage power consumption heat dissipation comparison similar synchronous designs
somewhat uncommon entire asynchronous cpu built without using global clock signal
two notable example arm compliant amulet mips r compatible minimips
rather totally removing clock signal cpu design allow certain portion device asynchronous using asynchronous alus conjunction superscalar pipelining achieve arithmetic performance gains
altogether clear whether totally asynchronous design perform comparable better level synchronous counterpart evident least excel simpler math operations
combined excellent power consumption heat dissipation property make suitable embedded computers
many modern cpu die-integrated power managing module regulates on-demand voltage supply cpu circuitry allowing keep balance performance power consumption
example early digital computer represented number familiar decimal base numeral system value others employed unusual representation ternary base three
nearly modern cpu represent number binary form digit represented two-valued physical quantity high low voltage
related numeric representation size precision integer number cpu represent
case binary cpu measured number bit significant digit binary encoded integer cpu process one operation commonly called word size bit width data path width integer precision integer size
cpu's integer size determines range integer value directly operate on
example bit cpu directly manipulate integer represented eight bit range discrete integer values
integer range also affect number memory location cpu directly address address integer value representing specific memory location
example binary cpu us bit represent memory address directly address memory locations
circumvent limitation various reason cpu use mechanism bank switching allow additional memory addressed
cpu larger word size require circuitry consequently physically larger cost consume power therefore generate heat
result smaller bit microcontrollers commonly used modern application even though cpu much larger word size even bit available
higher performance required however benefit larger word size larger data range address space may outweigh disadvantages
cpu internal data path shorter word size reduce size cost
example even though ibm system instruction set wa bit instruction set system model model bit data path arithmetic logical unit bit add required four cycle one bit operand even though motorola series instruction set wa bit instruction set motorola motorola
gain advantage afforded lower higher bit length many instruction set different bit width integer floating-point data allowing cpu implementing instruction set different bit width different portion device
example ibm system instruction set wa primarily bit supported bit floating point value facilitate greater accuracy range floating point numbers
system model bit adder decimal fixed-point binary arithmetic bit adder floating-point arithmetic
many later cpu design use similar mixed bit width especially processor meant general-purpose usage reasonable balance integer floating point capability required
description basic operation cpu offered previous section describes simplest form cpu take
type cpu usually referred subscalar operates executes one instruction one two piece data time le one instruction per clock cycle ipc
since one instruction executed time entire cpu must wait instruction complete proceeding next instruction
result subscalar cpu get hung instruction take one clock cycle complete execution
even adding second execution unit see doe improve performance much rather one pathway hung two pathway hung number unused transistor increased
design wherein cpu's execution resource operate one instruction time possibly reach scalar performance one instruction per clock cycle ipc
however performance nearly always subscalar le one instruction per clock cycle ipc
attempt achieve scalar better performance resulted variety design methodology cause cpu behave le linearly parallel
referring parallelism cpu two term generally used classify design techniques
instruction-level parallelism ilp seek increase rate instruction executed within cpu increase use on-die execution resources
task-level parallelism tlp purpose increase number thread process cpu execute simultaneouslyeach methodology differs way implemented well relative effectiveness afford increasing cpu's performance application
one simplest method increased parallelism begin first step instruction fetching decoding prior instruction finish executing
technique known instruction pipelining used almost modern general-purpose cpus
pipelining allows multiple instruction executed time breaking execution pathway discrete stages
separation compared assembly line instruction made complete stage exit execution pipeline retired
pipelining doe however introduce possibility situation result previous operation needed complete next operation condition often termed data dependency conflict
therefore pipelined processor must check sort condition delay portion pipeline necessary
pipelined processor become nearly scalar inhibited pipeline stall instruction spending one clock cycle stage
improvement instruction pipelining led decrease idle time cpu components
design said superscalar include long instruction pipeline multiple identical execution unit load-store unit arithmetic-logic unit floating-point unit address generation units
superscalar pipeline instruction read passed dispatcher decides whether instruction executed parallel simultaneously
general number instruction superscalar cpu complete cycle dependent number instruction able dispatch simultaneously execution units
difficulty design superscalar cpu architecture lie creating effective dispatcher
dispatcher need able quickly determine whether instruction executed parallel well dispatch way keep many execution unit busy possible
requires instruction pipeline filled often possible requires significant amount cpu cache
also make hazard-avoiding technique like branch prediction speculative execution register renaming out-of-order execution transactional memory crucial maintaining high level performance
attempting predict branch path conditional instruction take cpu minimize number time entire pipeline must wait conditional instruction completed
speculative execution often provides modest performance increase executing portion code may needed conditional operation completes
out-of-order execution somewhat rearranges order instruction executed reduce delay due data dependencies
also case single instruction stream multiple data streama case lot data type ha processed modern processor disable part pipeline single instruction executed many time cpu skip fetch decode phase thus greatly increase performance certain occasion especially highly monotonous program engine
case portion cpu superscalar part suffers performance penalty due scheduling stalls
intel p pentium two superscalar alus could accept one instruction per clock cycle fpu could not
thus p wa integer superscalar floating point superscalar
intel's successor p architecture p added superscalar ability floating point features
simple pipelining superscalar design increase cpu's ilp allowing execute instruction rate surpassing one instruction per clock cycle
modern cpu design least somewhat superscalar nearly general purpose cpu designed last decade superscalar
later year emphasis designing high-ilp computer ha moved cpu's hardware software interface instruction set architecture isa
strategy long instruction word vliw cause ilp become implied directly software reducing cpu work boosting ilp thereby reducing design complexity
another strategy achieving performance execute multiple thread process parallel
flynn's taxonomy strategy known multiple instruction stream multiple data stream mimd
initial flavor technology known symmetric multiprocessing smp small number cpu share coherent view memory system
scheme cpu ha additional hardware maintain constantly up-to-date view memory
avoiding stale view memory cpu cooperate program program migrate one cpu another
increase number cooperating cpu beyond handful scheme non-uniform memory access numa directory-based coherence protocol introduced s
smp system limited small number cpu numa system built thousand processors
initially multiprocessing wa built using multiple discrete cpu board implement interconnect processors
processor interconnect implemented single chip technology known chip-level multiprocessing cmp single chip multi-core processor
wa later recognized finer-grain parallelism existed single program
single program might several thread function could executed separately parallel
earliest example technology implemented inputoutput processing direct memory access separate thread computation thread
general approach technology wa introduced system designed run multiple computation thread parallel
approach considered cost-effective multiprocessing small number component within cpu replicated support mt opposed entire cpu case mp
mt execution unit memory system including cache shared among multiple threads
downside mt hardware support multithreading visible software mp thus supervisor software like operating system undergo larger change support mt
one type mt wa implemented known temporal multithreading one thread executed stalled waiting data return external memory
scheme cpu would quickly context switch another thread ready run switch often done one cpu clock cycle ultrasparc t
another type mt simultaneous multithreading instruction multiple thread executed parallel within one cpu clock cycle
several decade early focus designing high performance general purpose cpu wa largely achieving high ilp technology pipelining cache superscalar execution out-of-order execution etc
early cpu designer thwarted achieving higher performance ilp technique due growing disparity cpu operating frequency main memory operating frequency well escalating cpu power dissipation owing esoteric ilp techniques
cpu designer borrowed idea commercial computing market transaction processing aggregate performance multiple program also known throughput computing wa important performance single thread process
reversal emphasis evidenced proliferation dual core processor design notably intel's newer design resembling le superscalar p architecture
late design several processor family exhibit cmp including x opteron athlon x sparc ultrasparc ibm power power well several video game console cpu like xbox 's triple-core powerpc design playstation 's core cell microprocessor
le common increasingly important paradigm processor indeed computing general deal data parallelism
name implies vector processor deal multiple piece data context one instruction
contrast scalar processor deal one piece data every instruction
using flynn's taxonomy two scheme dealing data generally referred single instruction stream multiple data stream simd single instruction stream single data stream sisd respectively
great utility creating processor deal vector data lie optimizing task tend require operation example sum dot product performed large set data
classic example type task include multimedia application image video sound well many type scientific engineering tasks
whereas scalar processor must complete entire process fetching decoding executing instruction value set data vector processor perform single operation comparatively large set data one instruction
possible application tends require many step apply one operation large set data
early vector processor cray- associated almost exclusively scientific research cryptography applications
however multimedia ha largely shifted digital medium need form simd general-purpose processor ha become significant
shortly inclusion floating-point unit started become commonplace general-purpose processor specification implementation simd execution unit also began appear general-purpose processors
early simd specification like hp's multimedia acceleration extension max intel's mmx integer-only
proved significant impediment software developer since many application benefit simd primarily deal floating-point numbers
progressively developer refined remade early design common modern simd specification usually associated one instruction set architecture isa
notable modern example include intel's streaming simd extension sse powerpc-related altivec also known vmx
many modern architecture including embedded one often include hardware performance counter hpc enables low-level instruction-level collection benchmarking debugging analysis running software metrics
hpc may also used discover analyze unusual suspicious activity software return-oriented programming rop sigreturn-oriented programming srop exploit etc
usually done software-security team ass find malicious binary programs
many major vendor ibm intel amd arm etc provide software interface usually written cc used collected data cpu register order get metrics
operating system vendor also provide software like perf linux record benchmark trace cpu event running kernel applications
cloud computing involve subdividing cpu operation virtual central processing unit vcpus
host virtual equivalent physical machine virtual system operating
several physical machine operating tandem managed whole grouped computing memory resource form cluster
resource available host cluster level partitioned resource pool fine granularity
performance speed processor depends among many factor clock rate generally given multiple hertz instruction per clock ipc together factor instruction per second ip cpu perform
many reported ip value represented peak execution rate artificial instruction sequence branch whereas realistic workload consist mix instruction application take longer execute others
performance memory hierarchy also greatly affect processor performance issue barely considered mips calculations
problem various standardized test often called benchmark purposesuch specinthave developed attempt measure real effective performance commonly used applications
processing performance computer increased using multi-core processor essentially plugging two individual processor called core sense one integrated circuit
ideally dual core processor would nearly twice powerful single core processor
practice performance gain far smaller due imperfect software algorithm implementation
mean processor handle numerous asynchronous event interrupt etc
core thought different floor processing plant floor handling different task
sometimes core handle task core adjacent single core enough handle information
due specific capability modern cpu simultaneous multithreading uncore involve sharing actual cpu resource aiming increased utilization monitoring performance level hardware use gradually became complex task
response cpu implement additional hardware logic monitor actual use various part cpu provides various counter accessible software example intel's performance counter monitor technology
microchip shook world article institute electrical electronics enginee